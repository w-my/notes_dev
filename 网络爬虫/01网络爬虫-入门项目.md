# 网络爬虫-入门项目



## 项目环境

- JDK1.8
- IntelliJ IDEA
- IDEA 自带的 Maven



## 项目实现

创建 Maven 工程 java-crawler-01 ，并在 pom.xml 中加入依赖

```xml
<dependencies>
    <!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient -->
    <dependency>
        <groupId>org.apache.httpcomponents</groupId>
        <artifactId>httpclient</artifactId>
        <version>4.5.13</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 -->
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-log4j12</artifactId>
        <version>1.7.30</version>
        <!--<scope>test</scope>-->
    </dependency>
</dependencies>
```

在 resources 包中创建 log4j.properties 文件，并写入配置

```properties
log4j.rootLogger=DEBUG,A1
log4j.logger.cn.itcast = DEBUG

log4j.appender.A1=org.apache.log4j.ConsoleAppender
log4j.appender.A1.layout=org.apache.log4j.PatternLayout
log4j.appender.A1.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss,SSS} [%t] [%c]-[%p] %m%n
```

创建 cn.xx.crawler.test.CrawlerFirst.java

```java
public class CrawlerFirst {
    public static void main(String[] args) throws Exception {
        CloseableHttpClient httpClient = HttpClients.createDefault();
        HttpGet httpGet = new HttpGet("http://news.baidu.com/");
        CloseableHttpResponse response = httpClient.execute(httpGet);
        if (200 == response.getStatusLine().getStatusCode()) {
            String content = EntityUtils.toString(response.getEntity(), "UTF-8");
            System.out.println(content);
        }
    }
}
```

右键运行就可以爬到页面的数据
